# Policy Gradient

## Classic
- Better Convergence
- Effective in high-dimensional or continuous action spaces
- Can learn **stochastic** policies

- High-dimensional continuous control with generalized advantage estimation, Schulman et al. â€˜16
- Trust region policy optimization with value function approximation