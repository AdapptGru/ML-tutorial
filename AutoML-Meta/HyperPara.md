# Hyper Parameter

## Legacy
- Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. Sequential model-based optimization for general algorithm configuration. LION 2005

## Bayesian
- B. Shahriari, K. Swersky, Z. Wang, R. P. Adams, and N. de Freitas. Taking the human out of the loop: A review of bayesian optimization. 2016
- Jasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical bayesian optimization of machine learning algorithms. NIPS 2012
- Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Md. Mostofa Ali Patwary, Prabhat Prabhat, and Ryan P. Adams. Scalable bayesian optimization using deep neural networks. NIPS 2015

## New
- Frank Hutter, Lin Xu, Holger Hoos, and Kevin Leyton-Brown. Algorithm runtime prediction: Methods and evaluation (extended abstract). IJCAI 2015
- Tobias Domhan, Jost Tobias Springenberg, Frank Hutter. Speeding up Automatic Hyperparameter Optimization of Deep Neural Networksby Extrapolation of Learning Curves. IJCAI 2015
	- https://github.com/automl/pylearningcurvepredictor
- Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, Ameet Talwalkar. Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization, ICLR 2017
- Ha, David, Dai, Andrew, and Le, Quoc V. Hypernetworks.
In ICLR, 2017.
- J. Bergstra, R. Bardenet, Y. Bengio, and B. Kegl. Algo- ´
rithms for hyper-parameter optimization. In Neural Information
Processing Systems, 2011
- J. Bergstra and Y. Bengio. Random search for hyperparameter
optimization. Journal of Machine Learning Research,
13(Feb):281–305, 2012
- Elad Hazan, Adam Klivans, Yang Yuan. Hyperparameter Optimization: A Spectral Approach. NIPS DLTP Workshop 2017
	- https://github.com/callowbird/Harmonica
- Max Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech M. Czarnecki, Jeff Donahue, Ali Razavi, Oriol Vinyals, Tim Green, Iain Dunning, Karen Simonyan, Chrisantha Fernando, Koray Kavukcuoglu. Population Based Training of Neural Networks, 2017

## Gradient based hyper-parameter opt
- ICML 2015: Gradient-based hyperparameter optimization through reversible learning
- ICML 2016: Hyperparameter optimization with approximate gradient.